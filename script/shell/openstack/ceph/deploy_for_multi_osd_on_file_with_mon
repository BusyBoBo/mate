#!/bin/bash

set -e
set -u

if [[ "" == "$1" ]];then
    echo "args error..."
    exit 1
fi
DIR=$1
public_network=192.168.67.0/24
mon_addr=192.168.67.116

# install ceph here!!!

# get rid of process and directories leftovers
pkill ceph-mon || true
pkill ceph-osd || true
# rm -fr $DIR

# cluster wide parameters
mkdir -p ${DIR}/log
cat >> $DIR/ceph.conf <<EOF
[global]
fsid = $(uuidgen)
osd_crush_chooseleaf_type = 0
run_dir = ${DIR}/run
auth_cluster_required = none
auth_service_required = none
auth_client_required = none
osd_pool_default_size = 1
public_network = ${public_network}
EOF
export CEPH_ARGS="--conf ${DIR}/ceph.conf"

# single monitor
MON_DATA=${DIR}/mon
mkdir -p $MON_DATA

cat >> $DIR/ceph.conf <<EOF
[mon.0]
log_file = ${DIR}/log/mon.log
chdir = ""
mon_cluster_log_file = ${DIR}/log/mon-cluster.log
mon_data = ${MON_DATA}
mon_addr = ${mon_addr}
EOF

ceph-mon --id 0 --mkfs --keyring /dev/null
touch ${MON_DATA}/keyring
ceph-mon --id 0 

# single osd
OSD_DATA=${DIR}/osd
mkdir ${OSD_DATA}

cat >> $DIR/ceph.conf <<EOF
[osd.0]
log_file = ${DIR}/log/osd.log
chdir = ""
osd_data = ${OSD_DATA}
osd_journal = ${OSD_DATA}.journal
osd_journal_size = 5000
EOF

OSD_ID=$(ceph osd create)
ceph osd crush add osd.${OSD_ID} 1 root=default host=localhost
ceph-osd --id ${OSD_ID} --mkjournal --mkfs
ceph-osd --id ${OSD_ID}

# check that it works
ceph osd tree

# display usage instructions
echo export CEPH_ARGS="'--conf ${DIR}/ceph.conf'"
echo ceph osd tree
