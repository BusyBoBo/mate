#!/bin/bash

set -e
set -u

if [[ "" == "$1" ]];then
    echo "args error..."
    exit 1
fi

cluster='ceph'
ceph_root_dir='/var/lib/ceph'
ceph_conf='/etc/ceph/ceph.conf'
data_disks=$1
data_split_num=3
mon_addr=192.168.66.115
public_network=192.168.66.0/24

### 分区
journal_split_num=0
# 对各个磁盘分区
for disk in $data_disks; do
    disk=/dev/${disk}
    sgdisk -o ${disk}
    data_disk_size=`fdisk -l $disk  | grep "Disk ${disk}:" | awk '{print $5}'`
    # 转换成KB
    data_disk_size=$(( $data_disk_size/1024 ))
    split_disk_size=$(( $data_disk_size/$data_split_num ))
    ptype_tobe="89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be"
    for ((partnum=1;partnum<=$data_split_num;partnum++));do
        data_uuid=`uuidgen`
        start=$(( ($partnum-1)*$split_disk_size ))
        end=$(( $start+$split_disk_size-1 ))
        if [[ "$partnum" == "$data_split_num" ]]; then
            sgdisk --largest-new=$partnum \
                --change-name="$partnum:ceph data $partnum" \
                --partition-guid="$partnum:${data_uuid}" \
                --typecode="$partnum:${ptype_tobe}" \
                --mbrtogpt -- ${disk}
            break
        fi
        sgdisk --new="$partnum:${start}K:${end}K" \
            --change-name="$partnum:ceph data $partnum" \
            --partition-guid="$partnum:${data_uuid}" \
            --typecode="$partnum:${ptype_tobe}" \
            --mbrtogpt -- ${disk}
    done
    journal_split_num=$(( $journal_split_num + $data_split_num ))
done

echo "journal_split_num: $journal_split_num"

# 对journal disk分区
journal_disk=/dev/sdb
sgdisk -o ${journal_disk}
journal_disk_size=`fdisk -l $journal_disk  | grep "Disk $journal_disk:" | awk '{print $5}'`
journal_page_size=$(( $journal_disk_size/4096 )) # 4KB对齐
journal_page_size=$(( $journal_page_size*4/5 )) # 预留足够的空间20%，留作垃圾回收
split_page_size=$(( $journal_page_size/$journal_split_num ))
ptype='45b0969e-9b03-4f30-b4c6-b4b80ceff106'
for ((partnum=1;partnum<=$journal_split_num;partnum++));do
    journal_uuid=`uuidgen`
    start=$(( ($partnum-1)*$split_page_size ))
    end=$(( $start+$split_page_size-1 ))

    # 换算成KB
    start=$(( $start*4 ))
    end=$(( $end*4 ))
    sgdisk --new="$partnum:${start}K:${end}K" \
        --change-name="$partnum:ceph journal $partnum" \
        --partition-guid="$partnum:${journal_uuid}" \
        --typecode="$partnum:${ptype}" \
        --mbrtogpt -- $journal_disk
done

### 创建各个osd
pkill ceph-osd || true
host=`hostname`
data_disk_num=0
for disk in $data_disks; do
    for ((partnum=1;partnum<=$data_split_num;partnum++));do
        osd_id=$(ceph osd create)

        osd_data="${ceph_root_dir}/osd/${cluster}-${osd_id}"
        disk_part=${disk}${partnum}
        mkdir -p $osd_data
        mkfs -t xfs -f -i size=2048 /dev/$disk_part
        echo "osd${osd_id} use /dev/$disk_part, mounted on $osd_data"
        mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog /dev/$disk_part $osd_data

        # prepare for journal
        journal_partnum=$(( $data_split_num*$data_disk_num+$partnum ))
        journal_real_path=${journal_disk}${journal_partnum}
        journal_path=${osd_data}/journal
        ln -s $journal_real_path $journal_path

        cat >> $ceph_conf <<EOF
[osd.${osd_id}]
osd_data = ${osd_data}
osd_journal = ${journal_path}
# osd_journal_size = 1000
EOF
        ceph osd crush add osd.${osd_id} 1 root=default host=${host}
        ceph-osd --id ${osd_id} --mkfs --osd-journal $journal_path
        touch $osd_data/sysvinit
        service ceph start osd.${osd_id}
    done
    data_disk_num=$(( $data_disk_num+1 ))
done


# check that it works
# rados --pool data put group /etc/group
# rados --pool data get group ${ceph_root_dir}/group
# diff /etc/group ${ceph_root_dir}/group
# ceph osd tree

